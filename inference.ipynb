{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-04-28T16:38:42.874073Z",
     "start_time": "2025-04-28T16:38:42.744041Z"
    }
   },
   "source": [
    "import torch\n",
    "from models import BiTLikeModel\n",
    "\n",
    "# Load the model checkpoint\n",
    "checkpoint = torch.load('best.pt', map_location=torch.device('cpu'))\n",
    "\n",
    "# Initialize the model\n",
    "model = BiTLikeModel(2)  # Replace with your model class\n",
    "\n",
    "# Get the model's state_dict\n",
    "model_state_dict = model.state_dict()\n",
    "\n",
    "# Filter out mismatched keys (e.g., fc layer)\n",
    "filtered_checkpoint = {k: v for k, v in checkpoint.items() if k in model_state_dict and model_state_dict[k].shape == v.shape}\n",
    "\n",
    "# Load the compatible weights\n",
    "model_state_dict.update(filtered_checkpoint)\n",
    "model.load_state_dict(model_state_dict)\n",
    "\n",
    "# Reinitialize the fc layer\n",
    "torch.nn.init.xavier_uniform_(model.fc.weight)\n",
    "torch.nn.init.zeros_(model.fc.bias)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T16:38:43.291259Z",
     "start_time": "2025-04-28T16:38:43.286856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "def predict_image_class(model, image_path):\n",
    "    \"\"\"\n",
    "    Predicts the class of an image using the given model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model for inference.\n",
    "        image_path (str): Path to the image file.\n",
    "\n",
    "    Returns:\n",
    "        int: Predicted class index.\n",
    "    \"\"\"\n",
    "\n",
    "    preprocess = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),  # Resize to match the model's input size\n",
    "        transforms.ToTensor(),         # Convert image to tensor\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalize\n",
    "    ])\n",
    "\n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    input_tensor = preprocess(image).unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Perform inference\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        print(f\"output: {output}\")\n",
    "        probabilities = torch.softmax(output, dim=1)\n",
    "        print(f\"probabilities: {probabilities}\")\n",
    "\n",
    "    # Get the predicted class\n",
    "    predicted_class = torch.argmax(probabilities, dim=1).item()\n",
    "    print(f\"predicted_class: {predicted_class}\")\n",
    "    return predicted_class"
   ],
   "id": "cf141f303eb887af",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T17:34:44.001375Z",
     "start_time": "2025-04-28T17:34:43.763173Z"
    }
   },
   "cell_type": "code",
   "source": [
    "#testuojam\n",
    "\n",
    "# atsispaudzia\n",
    "image_path = 'test_data/ats1.jpeg'\n",
    "predict_image_class(model, image_path)\n",
    "image_path = 'test_data/ats2.jpeg'\n",
    "predict_image_class(model, image_path)\n",
    "\n",
    "print(\"=======================\")\n",
    "\n",
    "# stovi\n",
    "image_path = 'test_data/stov1.jpeg'\n",
    "predict_image_class(model, image_path)\n",
    "image_path = 'test_data/stov2.jpeg'\n",
    "predict_image_class(model, image_path)"
   ],
   "id": "f0547306258ad75b",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output: tensor([[-0.1558, -0.0863]])\n",
      "probabilities: tensor([[0.4826, 0.5174]])\n",
      "predicted_class: 1\n",
      "output: tensor([[-0.2289, -0.0077]])\n",
      "probabilities: tensor([[0.4449, 0.5551]])\n",
      "predicted_class: 1\n",
      "=======================\n",
      "output: tensor([[-0.0492, -0.1329]])\n",
      "probabilities: tensor([[0.5209, 0.4791]])\n",
      "predicted_class: 0\n",
      "output: tensor([[-0.0183, -0.1362]])\n",
      "probabilities: tensor([[0.5294, 0.4706]])\n",
      "predicted_class: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T16:34:27.986329Z",
     "start_time": "2025-04-28T16:34:27.983325Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "def capture_and_predict(model, capture_interval=5):\n",
    "    \"\"\"\n",
    "    Automatically captures images from the webcam at regular intervals and predicts their class using the given model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained model for inference.\n",
    "        capture_interval (int): Time interval (in seconds) between captures.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Initialize the webcam\n",
    "    cap = cv2.VideoCapture(0)\n",
    "    if not cap.isOpened():\n",
    "        raise Exception(\"Could not open webcam\")\n",
    "\n",
    "    print(\"Capturing images automatically. Press 'Esc' to exit.\")\n",
    "\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            print(\"Failed to grab frame\")\n",
    "            break\n",
    "\n",
    "        # Display the webcam feed\n",
    "        cv2.imshow(\"Webcam\", frame)\n",
    "\n",
    "        # Save the captured frame as a temporary image\n",
    "        temp_image_path = \"/tmp/temp_image.jpg\"\n",
    "        cv2.imwrite(temp_image_path, frame)\n",
    "        print(\"Image captured!\")\n",
    "\n",
    "        # Predict the class of the captured image\n",
    "        predicted_class = predict_image_class(model, temp_image_path)\n",
    "        print(f\"Predicted class: {predicted_class}\")\n",
    "\n",
    "        # play bell when prediction is 1\n",
    "        if predicted_class == 1:\n",
    "            os.system('play -nq --null --channels 1 synth 0.1 sine 444')\n",
    "        else:\n",
    "            os.system('play -nq --null --channels 1 synth 0.2 sine 1888')\n",
    "\n",
    "        # Remove the temporary image\n",
    "        os.remove(temp_image_path)\n",
    "\n",
    "        # Wait for the specified interval or until 'Esc' is pressed\n",
    "        if cv2.waitKey(capture_interval * 1000) == 27:  # Esc key to exit\n",
    "            break\n",
    "\n",
    "    # Release the webcam and close the window\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()"
   ],
   "id": "4ab91ce9607dd5d0",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2025-04-28T16:34:28.231478Z"
    }
   },
   "cell_type": "code",
   "source": "capture_and_predict(model)",
   "id": "7a4fbbaccb65390",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Capturing images automatically. Press 'Esc' to exit.\n",
      "Image captured!\n",
      "output: tensor([[ 0.0187, -0.2293]])\n",
      "probabilities: tensor([[0.5617, 0.4383]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0463, -0.0603]])\n",
      "probabilities: tensor([[0.5266, 0.4734]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0420, -0.1515]])\n",
      "probabilities: tensor([[0.5482, 0.4518]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0126, -0.1336]])\n",
      "probabilities: tensor([[0.5365, 0.4635]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0127, -0.1338]])\n",
      "probabilities: tensor([[0.5365, 0.4635]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0182, -0.1520]])\n",
      "probabilities: tensor([[0.5425, 0.4575]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0224, -0.1560]])\n",
      "probabilities: tensor([[0.5445, 0.4555]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0080, -0.1221]])\n",
      "probabilities: tensor([[0.5325, 0.4675]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0170, -0.1727]])\n",
      "probabilities: tensor([[0.5473, 0.4527]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0144, -0.1931]])\n",
      "probabilities: tensor([[0.5517, 0.4483]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0298, -0.0528]])\n",
      "probabilities: tensor([[0.5206, 0.4794]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n",
      "Image captured!\n",
      "output: tensor([[ 0.0332, -0.0755]])\n",
      "probabilities: tensor([[0.5272, 0.4728]])\n",
      "predicted_class: 0\n",
      "Predicted class: 0\n"
     ]
    }
   ],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T16:35:32.271498Z",
     "start_time": "2025-04-28T16:28:59.483942Z"
    }
   },
   "cell_type": "code",
   "source": "os.system('play -nq --null --channels 1 synth 0.5 sine 1840')",
   "id": "6b21bafadecabfc",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-28T16:35:32.287139Z",
     "start_time": "2025-04-28T16:12:58.764811Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Check if webcam is available\n",
    "import cv2\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "if not cap.isOpened():\n",
    "    print(\"Could not open webcam\")\n",
    "else:\n",
    "    print(\"Webcam initialized successfully\")\n",
    "cap.release()"
   ],
   "id": "811f4ef833f98cbb",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webcam initialized successfully\n"
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
