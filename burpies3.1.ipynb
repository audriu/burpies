{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12020,
     "status": "ok",
     "timestamp": 1745052700030,
     "user": {
      "displayName": "Audrius",
      "userId": "02601183058820550030"
     },
     "user_tz": -180
    },
    "id": "aRgEA6nUHQsp",
    "outputId": "8ae7b8d6-6214-4627-9318-837c82359919",
    "ExecuteTime": {
     "end_time": "2025-04-19T16:22:00.367777Z",
     "start_time": "2025-04-19T16:21:56.893520Z"
    }
   },
   "source": [
    "# Data annotations described here:\n",
    "# https://www.mpi-inf.mpg.de/departments/computer-vision-and-machine-learning/software-and-datasets/mpii-human-pose-dataset/download\n",
    "import scipy.io\n",
    "\n",
    "mat_file_path = 'content/mpii_human_pose_v1_u12_2/mpii_human_pose_v1_u12_1.mat'\n",
    "release_data = scipy.io.loadmat(mat_file_path)['RELEASE']\n",
    "print(f\"Fields inside 'RELEASE' structured array: {release_data.dtype.names}\")\n",
    "annolist = release_data['annolist'][0, 0]\n",
    "print(f\"Shape of 'annolist': {annolist.shape}\")\n",
    "\n",
    "\n",
    "first_image_annots = annolist[0, 0] # Or maybe annolist[0] depending on shape\n",
    "print(\"\\nInspecti----\", first_image_annots.dtype.names)\n",
    "print(first_image_annots['image'][0][0][0][0])\n",
    "\n",
    "act = release_data['act'][0, 0]\n",
    "\n",
    "print(f\"act ::: {act}\")\n",
    "\n",
    "filenames_map = {}\n",
    "\n",
    "\n",
    "for datum in range(annolist.shape[1]):  # Iterate through the second dimension of annolist\n",
    "    image_annot = annolist[0, datum]  # Access the element using index i in the second dimension\n",
    "    filename = image_annot['image'][0][0][0][0]  # Extract the filename\n",
    "\n",
    "    filenames_map[datum] = filename\n",
    "\n",
    "\n",
    "    if datum < 5:\n",
    "      print(f\"Filename for index {datum}: {filename}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fields inside 'RELEASE' structured array: ('annolist', 'img_train', 'version', 'single_person', 'act', 'video_list')\n",
      "Shape of 'annolist': (1, 24987)\n",
      "\n",
      "Inspecti---- ('image', 'annorect', 'frame_sec', 'vididx')\n",
      "037454012.jpg\n",
      "act ::: [[(array([], dtype='<U1'), array([], dtype='<U1'), array([[-1]], dtype=int16))]\n",
      " [(array([], dtype='<U1'), array([], dtype='<U1'), array([[-1]], dtype=int16))]\n",
      " [(array([], dtype='<U1'), array([], dtype='<U1'), array([[-1]], dtype=int16))]\n",
      " ...\n",
      " [(array(['transportation'], dtype='<U14'), array(['pushing car'], dtype='<U11'), array([[972]], dtype=uint16))]\n",
      " [(array([], dtype='<U1'), array([], dtype='<U1'), array([[-1]], dtype=int16))]\n",
      " [(array([], dtype='<U1'), array([], dtype='<U1'), array([[-1]], dtype=int16))]]\n",
      "Filename for index 0: 037454012.jpg\n",
      "Filename for index 1: 095071431.jpg\n",
      "Filename for index 2: 073199394.jpg\n",
      "Filename for index 3: 059865848.jpg\n",
      "Filename for index 4: 015601864.jpg\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 700,
     "status": "ok",
     "timestamp": 1745053914602,
     "user": {
      "displayName": "Audrius",
      "userId": "02601183058820550030"
     },
     "user_tz": -180
    },
    "id": "UOtUlqihPMMP",
    "outputId": "ec2bfbc1-d0e0-4090-8883-dc5b270c2a3b",
    "ExecuteTime": {
     "end_time": "2025-04-19T16:22:04.395780Z",
     "start_time": "2025-04-19T16:22:04.319365Z"
    }
   },
   "source": [
    "act = release_data['act'][0, 0]\n",
    "dataset = []\n",
    "number_skipped = 0\n",
    "activities_set = set()\n",
    "\n",
    "for datum, item in enumerate(act):\n",
    "    try:\n",
    "        cat_name = item[0][0][0] if len(item[0]) > 0 and len(item[0][0]) > 0 else None\n",
    "        act_name = item[0][1][0] if len(item[0]) > 1 and len(item[0][1]) > 0 else None\n",
    "        activities = str(act_name).split(\", \")\n",
    "        #act_id = item[0][2][0][0] if len(item[0]) > 2 and len(item[0][2]) > 0 else None\n",
    "        if not act_name:\n",
    "            number_skipped += 1\n",
    "            continue\n",
    "    except IndexError:\n",
    "        print(\"IndexError encountered. Skipping this item.\")\n",
    "        continue\n",
    "\n",
    "    dataset.append((\"content/images/\" + str(filenames_map[datum]), activities))\n",
    "    activities_set.update(activities)\n",
    "\n",
    "print(f\"number skipped: {number_skipped}\")\n",
    "\n",
    "\n",
    "# Ziurim ka turim. 🥸\n",
    "for i, datum in enumerate(dataset):\n",
    "    filename, act_name = datum\n",
    "    if i > 100:\n",
    "       break\n",
    "    print(f\"I: {i}. Filename {filename} act Name: {act_name}\")\n",
    "    #print(f\"{type(filename)}, Act Name: {type(act_name)}, Cat Name: {type(cat_name)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number skipped: 6954\n",
      "I: 0. Filename content/images/015601864.jpg act Name: ['curling']\n",
      "I: 1. Filename content/images/015599452.jpg act Name: ['curling']\n",
      "I: 2. Filename content/images/005808361.jpg act Name: ['curling']\n",
      "I: 3. Filename content/images/086617615.jpg act Name: ['curling']\n",
      "I: 4. Filename content/images/060111501.jpg act Name: ['curling']\n",
      "I: 5. Filename content/images/070807258.jpg act Name: ['curling']\n",
      "I: 6. Filename content/images/002058449.jpg act Name: ['curling']\n",
      "I: 7. Filename content/images/021233911.jpg act Name: ['sitting quietly']\n",
      "I: 8. Filename content/images/018182497.jpg act Name: ['sitting quietly']\n",
      "I: 9. Filename content/images/018340451.jpg act Name: ['sitting', 'talking in person', 'on the phone', 'computer', 'or text messaging', 'light effort']\n",
      "I: 10. Filename content/images/030424224.jpg act Name: ['sitting', 'talking in person', 'on the phone', 'computer', 'or text messaging', 'light effort']\n",
      "I: 11. Filename content/images/052475643.jpg act Name: ['sitting', 'talking in person', 'on the phone', 'computer', 'or text messaging', 'light effort']\n",
      "I: 12. Filename content/images/043194502.jpg act Name: ['sitting', 'talking in person', 'on the phone', 'computer', 'or text messaging', 'light effort']\n",
      "I: 13. Filename content/images/029122914.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 14. Filename content/images/061185289.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 15. Filename content/images/013949386.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 16. Filename content/images/029214465.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 17. Filename content/images/036636184.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 18. Filename content/images/045606998.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 19. Filename content/images/051423444.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 20. Filename content/images/059241457.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 21. Filename content/images/004645041.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 22. Filename content/images/060754485.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 23. Filename content/images/017052412.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 24. Filename content/images/006505159.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 25. Filename content/images/094888554.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 26. Filename content/images/096563203.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 27. Filename content/images/080839735.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 28. Filename content/images/030461377.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 29. Filename content/images/009767211.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 30. Filename content/images/068423303.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 31. Filename content/images/044015249.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 32. Filename content/images/012203823.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 33. Filename content/images/049517691.jpg act Name: ['truck driving', 'loading and unloading truck', 'tying down load', 'standing', 'walking and carrying heavy lo']\n",
      "I: 34. Filename content/images/003438852.jpg act Name: ['swimming', 'synchronized']\n",
      "I: 35. Filename content/images/031171108.jpg act Name: ['sitting quietly']\n",
      "I: 36. Filename content/images/052006802.jpg act Name: ['swimming', 'synchronized']\n",
      "I: 37. Filename content/images/054671028.jpg act Name: ['swimming', 'synchronized']\n",
      "I: 38. Filename content/images/018485446.jpg act Name: ['scrubbing floors']\n",
      "I: 39. Filename content/images/096958463.jpg act Name: ['mopping', 'standing', 'light effort']\n",
      "I: 40. Filename content/images/077513282.jpg act Name: ['mopping', 'standing', 'light effort']\n",
      "I: 41. Filename content/images/093949894.jpg act Name: ['mopping', 'standing', 'light effort']\n",
      "I: 42. Filename content/images/089482735.jpg act Name: ['mopping', 'standing', 'light effort']\n",
      "I: 43. Filename content/images/059789998.jpg act Name: ['mopping', 'standing', 'light effort']\n",
      "I: 44. Filename content/images/092187424.jpg act Name: ['mopping', 'standing', 'light effort']\n",
      "I: 45. Filename content/images/008849250.jpg act Name: ['chambermaid', 'hotel housekeeper', 'making bed', 'cleaning bathroom', 'pushing cart']\n",
      "I: 46. Filename content/images/019598286.jpg act Name: ['cleaning', 'general']\n",
      "I: 47. Filename content/images/004522729.jpg act Name: ['chambermaid', 'hotel housekeeper', 'making bed', 'cleaning bathroom', 'pushing cart']\n",
      "I: 48. Filename content/images/082873751.jpg act Name: ['implied walkingstanding - picking up yard', 'light', 'picking flowers or vegetables']\n",
      "I: 49. Filename content/images/035675333.jpg act Name: ['implied walkingstanding - picking up yard', 'light', 'picking flowers or vegetables']\n",
      "I: 50. Filename content/images/028093451.jpg act Name: ['implied walkingstanding - picking up yard', 'light', 'picking flowers or vegetables']\n",
      "I: 51. Filename content/images/098688694.jpg act Name: ['implied walkingstanding - picking up yard', 'light', 'picking flowers or vegetables']\n",
      "I: 52. Filename content/images/077224477.jpg act Name: ['implied walkingstanding - picking up yard', 'light', 'picking flowers or vegetables']\n",
      "I: 53. Filename content/images/019871568.jpg act Name: ['implied walkingstanding - picking up yard', 'light', 'picking flowers or vegetables']\n",
      "I: 54. Filename content/images/000552212.jpg act Name: ['implied walkingstanding - picking up yard', 'light', 'picking flowers or vegetables']\n",
      "I: 55. Filename content/images/035846573.jpg act Name: ['sitting', 'talking in person', 'on the phone', 'computer', 'or text messaging', 'light effort']\n",
      "I: 56. Filename content/images/011586906.jpg act Name: ['sitting', 'talking in person', 'on the phone', 'computer', 'or text messaging', 'light effort']\n",
      "I: 57. Filename content/images/086310343.jpg act Name: ['gardening', 'general', 'moderate effort']\n",
      "I: 58. Filename content/images/062329813.jpg act Name: ['implied walkingstanding - picking up yard', 'light', 'picking flowers or vegetables']\n",
      "I: 59. Filename content/images/006355835.jpg act Name: ['standing', 'talking in person']\n",
      "I: 60. Filename content/images/031098232.jpg act Name: ['standing', 'talking in person']\n",
      "I: 61. Filename content/images/032518332.jpg act Name: ['standing', 'talking in person']\n",
      "I: 62. Filename content/images/072960618.jpg act Name: ['standing', 'miscellaneous']\n",
      "I: 63. Filename content/images/063755747.jpg act Name: ['standing', 'talking in person']\n",
      "I: 64. Filename content/images/088721274.jpg act Name: ['lawn bowling', 'bocce ball', 'outdoor']\n",
      "I: 65. Filename content/images/047221493.jpg act Name: ['lawn bowling', 'bocce ball', 'outdoor']\n",
      "I: 66. Filename content/images/011959425.jpg act Name: ['lawn bowling', 'bocce ball', 'outdoor']\n",
      "I: 67. Filename content/images/071324479.jpg act Name: ['lawn bowling', 'bocce ball', 'outdoor']\n",
      "I: 68. Filename content/images/076078505.jpg act Name: ['lawn bowling', 'bocce ball', 'outdoor']\n",
      "I: 69. Filename content/images/056127720.jpg act Name: ['serving food in church']\n",
      "I: 70. Filename content/images/077096718.jpg act Name: ['serving food in church']\n",
      "I: 71. Filename content/images/049379560.jpg act Name: ['serving food in church']\n",
      "I: 72. Filename content/images/042754102.jpg act Name: ['skiing', 'downhill']\n",
      "I: 73. Filename content/images/002541913.jpg act Name: ['skiing', 'downhill']\n",
      "I: 74. Filename content/images/010789143.jpg act Name: ['skiing', 'downhill']\n",
      "I: 75. Filename content/images/003142919.jpg act Name: ['skiing', 'downhill']\n",
      "I: 76. Filename content/images/063641041.jpg act Name: ['skiing', 'downhill']\n",
      "I: 77. Filename content/images/031435598.jpg act Name: ['skiing', 'cross-country']\n",
      "I: 78. Filename content/images/050857069.jpg act Name: ['skiing', 'cross-country']\n",
      "I: 79. Filename content/images/090756647.jpg act Name: ['skiing', 'downhill']\n",
      "I: 80. Filename content/images/024929223.jpg act Name: ['skiing', 'downhill']\n",
      "I: 81. Filename content/images/041038292.jpg act Name: ['skiing', 'downhill']\n",
      "I: 82. Filename content/images/075555114.jpg act Name: ['skiing', 'downhill']\n",
      "I: 83. Filename content/images/022879817.jpg act Name: ['skiing', 'climbing up']\n",
      "I: 84. Filename content/images/007697991.jpg act Name: ['skiing', 'climbing up']\n",
      "I: 85. Filename content/images/016122129.jpg act Name: ['skiing', 'climbing up']\n",
      "I: 86. Filename content/images/092969765.jpg act Name: ['skiing', 'climbing up']\n",
      "I: 87. Filename content/images/080812038.jpg act Name: ['skiing', 'climbing up']\n",
      "I: 88. Filename content/images/063340376.jpg act Name: ['skiing', 'downhill']\n",
      "I: 89. Filename content/images/087146059.jpg act Name: ['skiing', 'climbing up']\n",
      "I: 90. Filename content/images/080367208.jpg act Name: ['skiing', 'climbing up']\n",
      "I: 91. Filename content/images/018657006.jpg act Name: ['skiing', 'climbing up']\n",
      "I: 92. Filename content/images/089255900.jpg act Name: ['skiing', 'downhill']\n",
      "I: 93. Filename content/images/053934224.jpg act Name: ['horse grooming', 'feeding', 'cleaning', 'harnessing and unharnessing']\n",
      "I: 94. Filename content/images/080744016.jpg act Name: ['horse grooming', 'feeding', 'cleaning', 'harnessing and unharnessing']\n",
      "I: 95. Filename content/images/089609130.jpg act Name: ['horse cart', 'driving', 'standing or sitting']\n",
      "I: 96. Filename content/images/031800347.jpg act Name: ['horse cart', 'driving', 'standing or sitting']\n",
      "I: 97. Filename content/images/011005192.jpg act Name: ['horse grooming', 'feeding', 'cleaning', 'harnessing and unharnessing']\n",
      "I: 98. Filename content/images/022793516.jpg act Name: ['horse grooming', 'feeding', 'cleaning', 'harnessing and unharnessing']\n",
      "I: 99. Filename content/images/086073058.jpg act Name: ['horse grooming', 'feeding', 'cleaning', 'harnessing and unharnessing']\n",
      "I: 100. Filename content/images/000695213.jpg act Name: ['horse grooming', 'feeding', 'cleaning', 'harnessing and unharnessing']\n"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 45,
     "status": "ok",
     "timestamp": 1745052339247,
     "user": {
      "displayName": "Audrius",
      "userId": "02601183058820550030"
     },
     "user_tz": -180
    },
    "id": "o2oEoH61DVas",
    "outputId": "36884740-d578-4bf1-fdd9-8f7807d913c3",
    "ExecuteTime": {
     "end_time": "2025-04-19T16:22:52.737750Z",
     "start_time": "2025-04-19T16:22:50.640926Z"
    }
   },
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Define the custom dataset class\n",
    "class MPIIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, act_name = self.data[idx]\n",
    "        image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Return the image and label (adjust label processing as needed)\n",
    "        return image, act_name\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create a label encoder for activities\n",
    "label_encoder = LabelEncoder()\n",
    "all_activities = list(activities_set)\n",
    "label_encoder.fit(all_activities)\n",
    "\n",
    "# Update the MPIIDataset class\n",
    "class MPIIDataset(Dataset):\n",
    "    def __init__(self, data, transform=None):\n",
    "        self.data = data\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path, act_name = self.data[idx]\n",
    "        image = Image.open(image_path).convert('RGB')  # Ensure RGB format\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        # Convert activity name(s) to numerical label(s)\n",
    "        label = label_encoder.transform(act_name)  # Convert to numerical indices\n",
    "        label = label[0] if len(label) > 0 else 0  # Handle single-label case\n",
    "\n",
    "        return image, label\n",
    "\n",
    "# Split the dataset into train, validation, and test sets\n",
    "# You can adjust the split ratios as needed\n",
    "train_ratio = 0.8\n",
    "val_ratio = 0.1\n",
    "test_ratio = 0.1\n",
    "\n",
    "train_size = int(len(dataset) * train_ratio)\n",
    "val_size = int(len(dataset) * val_ratio)\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset = []\n",
    "val_dataset = []\n",
    "test_dataset = []\n",
    "# Create a dictionary to hold the dataset\n",
    "\n",
    "train_size = int(len(dataset) * train_ratio)\n",
    "val_size = int(len(dataset) * val_ratio)\n",
    "\n",
    "# Assign elements to datasets based on key index\n",
    "for i in range(len(dataset)):\n",
    "    if i < train_size:\n",
    "        train_dataset.append(dataset[i])\n",
    "    elif i < train_size + val_size:\n",
    "        val_dataset.append(dataset[i])\n",
    "    else:\n",
    "        test_dataset.append(dataset[i])\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(val_dataset)}\")\n",
    "print(f\"Test dataset size: {len(test_dataset)}\")\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize(256),  # Resize the images\n",
    "    transforms.CenterCrop(224),  # Crop the images\n",
    "    transforms.ToTensor(),  # Convert to a tensor\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  # Normalize the images\n",
    "])\n",
    "\n",
    "train_dataset = MPIIDataset(train_dataset, transform=transform)\n",
    "val_dataset = MPIIDataset(val_dataset, transform=transform)\n",
    "test_dataset = MPIIDataset(test_dataset, transform=transform)\n",
    "\n",
    "# Create data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 14426\n",
      "Validation dataset size: 1803\n",
      "Test dataset size: 1804\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 391
    },
    "executionInfo": {
     "elapsed": 1074,
     "status": "error",
     "timestamp": 1745052386346,
     "user": {
      "displayName": "Audrius",
      "userId": "02601183058820550030"
     },
     "user_tz": -180
    },
    "id": "_qa54PG2J0Hy",
    "outputId": "27159fba-3ceb-4980-cdb1-2bac5f5ea9f8",
    "ExecuteTime": {
     "end_time": "2025-04-19T16:27:08.550170Z",
     "start_time": "2025-04-19T16:26:17.647363Z"
    }
   },
   "source": [
    "# prompt: generate me pytorch model that trains on beforementioned dataloders\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Define the model architecture\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(128 * 56 * 56, 256), # Adjust input size based on image dimensions after conv layers.\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(256, num_classes),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "# Assuming you have num_classes\n",
    "num_classes = len(activities_set)\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes).to(device)\n",
    "criterion = nn.CrossEntropyLoss()  # Use appropriate loss based on your task\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10  # Adjust the number of epochs\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels in tqdm(train_loader): # Use tqdm for progress bar\n",
    "        images, labels = images.to(device), labels.to(device)  # Move data to the device\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "# Validation/Testing\n",
    "model.eval()\n",
    "# ... (Add your validation or testing loop here)\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 18/451 [00:49<19:50,  2.75s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[5]\u001B[39m\u001B[32m, line 47\u001B[39m\n\u001B[32m     44\u001B[39m model.train()\n\u001B[32m     45\u001B[39m running_loss = \u001B[32m0.0\u001B[39m\n\u001B[32m---> \u001B[39m\u001B[32m47\u001B[39m \u001B[43m\u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m)\u001B[49m\u001B[43m:\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;66;43;03m# Use tqdm for progress bar\u001B[39;49;00m\n\u001B[32m     48\u001B[39m \u001B[43m    \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m \u001B[49m\u001B[43m=\u001B[49m\u001B[43m \u001B[49m\u001B[43mimages\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mlabels\u001B[49m\u001B[43m.\u001B[49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Move data to the device\u001B[39;49;00m\n\u001B[32m     49\u001B[39m \u001B[43m    \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mzero_grad\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/development/burpies/.venv/lib/python3.12/site-packages/tqdm/std.py:1181\u001B[39m, in \u001B[36mtqdm.__iter__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m   1178\u001B[39m time = \u001B[38;5;28mself\u001B[39m._time\n\u001B[32m   1180\u001B[39m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1181\u001B[39m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43miterable\u001B[49m\u001B[43m:\u001B[49m\n\u001B[32m   1182\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;28;43;01myield\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mobj\u001B[49m\n\u001B[32m   1183\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Update and possibly print the progressbar.\u001B[39;49;00m\n\u001B[32m   1184\u001B[39m \u001B[43m        \u001B[49m\u001B[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;49;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/development/burpies/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:708\u001B[39m, in \u001B[36m_BaseDataLoaderIter.__next__\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    705\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    706\u001B[39m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[32m    707\u001B[39m     \u001B[38;5;28mself\u001B[39m._reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m708\u001B[39m data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    709\u001B[39m \u001B[38;5;28mself\u001B[39m._num_yielded += \u001B[32m1\u001B[39m\n\u001B[32m    710\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[32m    711\u001B[39m     \u001B[38;5;28mself\u001B[39m._dataset_kind == _DatasetKind.Iterable\n\u001B[32m    712\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m    713\u001B[39m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m._num_yielded > \u001B[38;5;28mself\u001B[39m._IterableDataset_len_called\n\u001B[32m    714\u001B[39m ):\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/development/burpies/.venv/lib/python3.12/site-packages/torch/utils/data/dataloader.py:764\u001B[39m, in \u001B[36m_SingleProcessDataLoaderIter._next_data\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    762\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[32m    763\u001B[39m     index = \u001B[38;5;28mself\u001B[39m._next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m--> \u001B[39m\u001B[32m764\u001B[39m     data = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[43m.\u001B[49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[32m    765\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m._pin_memory:\n\u001B[32m    766\u001B[39m         data = _utils.pin_memory.pin_memory(data, \u001B[38;5;28mself\u001B[39m._pin_memory_device)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/development/burpies/.venv/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py:52\u001B[39m, in \u001B[36m_MapDatasetFetcher.fetch\u001B[39m\u001B[34m(self, possibly_batched_index)\u001B[39m\n\u001B[32m     50\u001B[39m         data = \u001B[38;5;28mself\u001B[39m.dataset.__getitems__(possibly_batched_index)\n\u001B[32m     51\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m---> \u001B[39m\u001B[32m52\u001B[39m         data = [\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n\u001B[32m     53\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m     54\u001B[39m     data = \u001B[38;5;28mself\u001B[39m.dataset[possibly_batched_index]\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[3]\u001B[39m\u001B[32m, line 42\u001B[39m, in \u001B[36mMPIIDataset.__getitem__\u001B[39m\u001B[34m(self, idx)\u001B[39m\n\u001B[32m     40\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34m__getitem__\u001B[39m(\u001B[38;5;28mself\u001B[39m, idx):\n\u001B[32m     41\u001B[39m     image_path, act_name = \u001B[38;5;28mself\u001B[39m.data[idx]\n\u001B[32m---> \u001B[39m\u001B[32m42\u001B[39m     image = \u001B[43mImage\u001B[49m\u001B[43m.\u001B[49m\u001B[43mopen\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimage_path\u001B[49m\u001B[43m)\u001B[49m\u001B[43m.\u001B[49m\u001B[43mconvert\u001B[49m\u001B[43m(\u001B[49m\u001B[33;43m'\u001B[39;49m\u001B[33;43mRGB\u001B[39;49m\u001B[33;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Ensure RGB format\u001B[39;00m\n\u001B[32m     44\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.transform:\n\u001B[32m     45\u001B[39m         image = \u001B[38;5;28mself\u001B[39m.transform(image)\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/development/burpies/.venv/lib/python3.12/site-packages/PIL/Image.py:982\u001B[39m, in \u001B[36mImage.convert\u001B[39m\u001B[34m(self, mode, matrix, dither, palette, colors)\u001B[39m\n\u001B[32m    979\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m mode \u001B[38;5;129;01min\u001B[39;00m (\u001B[33m\"\u001B[39m\u001B[33mBGR;15\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mBGR;16\u001B[39m\u001B[33m\"\u001B[39m, \u001B[33m\"\u001B[39m\u001B[33mBGR;24\u001B[39m\u001B[33m\"\u001B[39m):\n\u001B[32m    980\u001B[39m     deprecate(mode, \u001B[32m12\u001B[39m)\n\u001B[32m--> \u001B[39m\u001B[32m982\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mload\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    984\u001B[39m has_transparency = \u001B[33m\"\u001B[39m\u001B[33mtransparency\u001B[39m\u001B[33m\"\u001B[39m \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m.info\n\u001B[32m    985\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m mode \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m.mode == \u001B[33m\"\u001B[39m\u001B[33mP\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m    986\u001B[39m     \u001B[38;5;66;03m# determine default mode\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~/development/burpies/.venv/lib/python3.12/site-packages/PIL/ImageFile.py:389\u001B[39m, in \u001B[36mImageFile.load\u001B[39m\u001B[34m(self)\u001B[39m\n\u001B[32m    386\u001B[39m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mOSError\u001B[39;00m(msg)\n\u001B[32m    388\u001B[39m b = b + s\n\u001B[32m--> \u001B[39m\u001B[32m389\u001B[39m n, err_code = \u001B[43mdecoder\u001B[49m\u001B[43m.\u001B[49m\u001B[43mdecode\u001B[49m\u001B[43m(\u001B[49m\u001B[43mb\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    390\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m n < \u001B[32m0\u001B[39m:\n\u001B[32m    391\u001B[39m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyNile9U0808ofRr1kr5fuAO",
   "provenance": [
    {
     "file_id": "1eB0nuAC7S_9DNy-XH2Q67CO4SeWXb75L",
     "timestamp": 1744650477063
    }
   ]
  },
  "kernelspec": {
   "display_name": "burpies_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
